{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Dataset\n",
    "\n",
    "http://www.bbci.de/competition/iii/desc_IVa.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib:CACHEDIR=/home/nahuel/.cache/matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /home/nahuel/.cache/matplotlib/fontlist-v310.json\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.io import loadmat\n",
    "import matplotlib as mpl\n",
    "from wyrm import processing as proc\n",
    "from wyrm.types import Data\n",
    "from wyrm import plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se carga data txt Class-Time x Channel (298458 x 118)\n",
    "#    #tr  #te\n",
    "#aa  168 112\n",
    "#al  224  56\n",
    "#av  84  196\n",
    "#aw  56  224\n",
    "#ay  28  252\n",
    "\n",
    "# /home/nahuel/Documents/TESIS/DATA/Competencia BCI/III/Dataset_IV/txt\n",
    "\n",
    "sujeto='aa'\n",
    "nro_tr=168\n",
    "data_cnt_txt = np.loadtxt('../../DATA/Competencia BCI/III/Dataset_IV/txt/'+sujeto+'/100Hz/data_set_IVa_'+sujeto+'_cnt.txt')\n",
    "#Traspuesta Channel x Class-Time (118 x 298458)\n",
    "data_cnt_txt = data_cnt_txt.transpose()\n",
    "\n",
    "#Se carga 280 etiquetas de Class\n",
    "data_lab_txt = np.loadtxt('../../DATA/Competencia BCI/III/Dataset_IV/txt/'+sujeto+'/100Hz/data_set_IVa_'+sujeto+'_mrk.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se carga 100 etiquetas TRUE LABELS\n",
    "TRUE_LABELS = '../../DATA/Competencia BCI/III/Dataset_IV/txt/'+sujeto+'/TRUE_LABELS.txt'\n",
    "\n",
    "true_labels = np.loadtxt(TRUE_LABELS).astype('int')\n",
    "#Convertimos los -1 a 0\n",
    "true_labels[true_labels == 2] = 0\n",
    "\n",
    "true_labels = true_labels[nro_tr:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se castea a Int (1- Left, 2- Foot, 0- Test)\n",
    "data_lab_txt = np.nan_to_num(data_lab_txt)\n",
    "data_lab_txt = data_lab_txt.astype('int')\n",
    "\n",
    "#La primer columna es de posiciones de eventos\n",
    "posicion = data_lab_txt[:,0]\n",
    "#La segunda columna es de labels\n",
    "data_lab = data_lab_txt[:,1]\n",
    "\n",
    "flag=1\n",
    "for pos in posicion:\n",
    "    #Nos quedamos con muestras de 60 frames por evento para los 118 channels\n",
    "    aux = np.array( [ data_cnt_txt[:, pos-30:pos+30] ] )\n",
    "    if flag == 1:\n",
    "        data_cnt=aux\n",
    "        flag=0\n",
    "    else:\n",
    "        data_cnt=np.append(data_cnt, aux, axis=0)\n",
    "        \n",
    "\n",
    "#Modificamos el orden de las dimensiones como Class x Time x Channel (280 x 60 x 118)\n",
    "data_cnt=data_cnt.swapaxes(-1, -2)\n",
    "\n",
    "#Los primeros 168 Class son de train como Class x Time x Channel (168 x 60 x 118)\n",
    "data_train=data_cnt[:nro_tr]\n",
    "#El resto de las Class son de test como Class x Time x Channel (112 x 60 x 118)\n",
    "data_test=data_cnt[nro_tr:]\n",
    "\n",
    "\n",
    "#Las labes validas son para el conjunto de train\n",
    "data_lab = data_lab[:nro_tr]\n",
    "data_lab[data_lab == 2] = 0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos a wyrm Data - Set Train\n",
    "#Cargamos data training\n",
    "data = data_train\n",
    "labels = data_lab\n",
    "\n",
    "#Creamos axes con enumerados de la misma longitud que data Class x Time x Channel\n",
    "axes = [np.arange(i) for i in data.shape]\n",
    "#Se completa la dimension Class con labels\n",
    "axes[0] = labels\n",
    "#Se convierte a str la dimension Channel\n",
    "#axes[2] = [str(i) for i in range(data.shape[2])]\n",
    "axes[2] = ['Fp1', 'AFp1', 'Fpz', 'AFp2', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'FAF5', 'FAF1', 'FAF2', 'FAF6', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FFC7', 'FFC5', 'FFC3', 'FFC1', 'FFC2', 'FFC4', 'FFC6', 'FFC8', 'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'CFC7', 'CFC5', 'CFC3', 'CFC1', 'CFC2', 'CFC4', 'CFC6', 'CFC8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'CCP7', 'CCP5', 'CCP3', 'CCP1', 'CCP2', 'CCP4', 'CCP6', 'CCP8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10', 'PCP7', 'PCP5', 'PCP3', 'PCP1', 'PCP2', 'PCP4', 'PCP6', 'PCP8', 'P9', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'P10', 'PPO7', 'PPO5', 'PPO1', 'PPO2', 'PPO6', 'PPO8', 'PO7', 'PO3', 'PO1', 'POz', 'PO2', 'PO4', 'PO8', 'OPO1', 'OPO2', 'O1', 'Oz', 'O2', 'OI1', 'OI2', 'I1', 'I2' ]\n",
    "\n",
    "names = ['Class', 'Time', 'Channel']\n",
    "units = ['#', 'ms', '#']\n",
    "dat_train = Data(data=data, axes=axes, names=names, units=units)\n",
    "dat_train.fs = 100\n",
    "dat_train.class_names = ['Left', 'Foot']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos a wyrm Data - Set Test\n",
    "#Cargamos data test\n",
    "data = data_test\n",
    "\n",
    "#Creamos axes con enumerados de la misma longitud que data Class x Time x Channel\n",
    "axes = [np.arange(i) for i in data.shape]\n",
    "#Se convierte a str la dimension Channel\n",
    "axes[2] = [str(i) for i in range(data.shape[2])]\n",
    "names = ['Epoch', 'Time', 'Channel']\n",
    "units = ['#', 'ms', '#']\n",
    "dat_test = Data(data=data, axes=axes, names=names, units=units)\n",
    "dat_test.fs = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_csp_pattern(a):\n",
    "    # get symmetric min/max values for the color bar from first and last column of the pattern\n",
    "    maxv = np.max(np.abs(a[:, [0, -1]]))\n",
    "    minv = -maxv\n",
    "    \n",
    "    im_args = {'interpolation' : 'None', \n",
    "           'vmin' : minv, \n",
    "           'vmax' : maxv\n",
    "           }\n",
    "\n",
    "    # plot\n",
    "    ax1 = plt.subplot2grid((1,11), (0,0), colspan=5)\n",
    "    ax2 = plt.subplot2grid((1,11), (0,5), colspan=5)\n",
    "    ax3 = plt.subplot2grid((1,11), (0,10))\n",
    "\n",
    "    ax1.imshow(a[:, 0].reshape(8, 8), **im_args)\n",
    "    ax1.set_title('Pinky')\n",
    "\n",
    "    ax = ax2.imshow(a[:, -1].reshape(8, 8), **im_args)\n",
    "    ax2.set_title('Tongue')\n",
    "\n",
    "    plt.colorbar(ax, cax=ax3)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtros(data):\n",
    "    dat = data.copy()\n",
    "    \n",
    "    #Mitad de la frecuencia\n",
    "    fs_n = dat.fs / 2\n",
    "    \n",
    "    #Se aplica filtros\n",
    "    b, a = proc.signal.butter(5, [13 / fs_n], btype='low')   \n",
    "    dat = proc.filtfilt(dat, b, a)\n",
    "    \n",
    "    b, a = proc.signal.butter(5, [9 / fs_n], btype='high')\n",
    "    dat = proc.filtfilt(dat, b, a)\n",
    "    return dat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, filt=None):\n",
    "    #Se aplican los filtros\n",
    "    dat=filtros(data)\n",
    "    \n",
    "    #Se toma una muestra de 50 cada 1000 (fs_n = 1000) (278 x 150 x 64)\n",
    "    dat = proc.subsample(dat, 50)\n",
    "        \n",
    "    if filt is None:\n",
    "        #Calcula el patrón espacial común (CSP) para dos clases.\n",
    "        filt, pattern, _ = proc.calculate_csp(dat)\n",
    "        #Grafica csp_pattern\n",
    "        #plot_csp_pattern(pattern)\n",
    "        \n",
    "    #Aplica el CSP\n",
    "    dat = proc.apply_csp(dat, filt)\n",
    "    #print(filt[0])\n",
    "    dat = proc.variance(dat)\n",
    "    dat = proc.logarithm(dat)\n",
    "    return dat, filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:wyrm.misc:apply_csp is deprecated since version 1.1. Please use apply_spatial_filter instead.\n",
      "WARNING:wyrm.misc:apply_csp is deprecated since version 1.1. Please use apply_spatial_filter instead.\n"
     ]
    }
   ],
   "source": [
    "#Se calcula el vector de caracteristicas para los conjuntos de train y test\n",
    "fv_train, filt = preprocess(dat_train)\n",
    "fv_test, _ = preprocess(dat_test, filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dat_new = proc.remove_channels(dat_train, ['PPO4','CP4'])\n",
    "#proc.select_channels(dat_train, ['PPO4','CP4'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LDA Accuracy 0.55%\n"
     ]
    }
   ],
   "source": [
    "#Entrenamiento con LDA clasificador.\n",
    "cfy = proc.lda_train(fv_train)\n",
    "\n",
    "#Aplicar vector de características al clasificador LDA.\n",
    "result = proc.lda_apply(fv_test, cfy)\n",
    "\n",
    "#Normaliza resultados\n",
    "#Si es > 0 = 1 sino -1\n",
    "result = (np.sign(result)).astype('int')\n",
    "#Convertimos los -1 a 0\n",
    "result[result == -1] = 0\n",
    "\n",
    "#Se compara los resultados del modelo contra los TRUE LABELS\n",
    "print ('LDA Accuracy %.2f%%' % ((result == true_labels).sum() / len(result)) ) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(112,)\n",
      "(112,)\n",
      "[[27 25]\n",
      " [25 35]]\n",
      "Recall:  [0.51923077 0.58333333]\n",
      "Precision:  [0.51923077 0.58333333]\n",
      "F1:  [0.51923077 0.58333333]\n",
      "Acurracy:  0.5535714285714286\n",
      "27 25 25 35\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.52      0.52      0.52        52\n",
      "           1       0.58      0.58      0.58        60\n",
      "\n",
      "    accuracy                           0.55       112\n",
      "   macro avg       0.55      0.55      0.55       112\n",
      "weighted avg       0.55      0.55      0.55       112\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics as met\n",
    "\n",
    "print(true_labels.shape)\n",
    "print(result.shape)\n",
    "\n",
    "print( met.confusion_matrix(true_labels, result) )\n",
    "print( \"Recall: \", met.recall_score(true_labels, result, average=None) )\n",
    "print( \"Precision: \", met.precision_score(true_labels, result, average=None) )\n",
    "print( \"F1: \", met.f1_score(true_labels, result, average=None) )\n",
    "print( \"Acurracy: \", met.accuracy_score(true_labels, result) )\n",
    "\n",
    "tn, fp, fn, tp = met.confusion_matrix(true_labels, result).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(met.classification_report(true_labels, result))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix :\n",
      "[[3 3]\n",
      " [1 3]]\n",
      "Accuracy Score is 0.6\n",
      "Classification Report : \n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.75      0.50      0.60         6\n",
      "           1       0.50      0.75      0.60         4\n",
      "\n",
      "    accuracy                           0.60        10\n",
      "   macro avg       0.62      0.62      0.60        10\n",
      "weighted avg       0.65      0.60      0.60        10\n",
      "\n",
      "AUC-ROC: 0.625\n",
      "LOGLOSS Value is 13.815750437193334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import log_loss\n",
    "X_actual = [1, 1, 0, 1, 0, 0, 1, 0, 0, 0]\n",
    "Y_predic = [1, 0, 1, 1, 1, 0, 1, 1, 0, 0]\n",
    "results = confusion_matrix(X_actual, Y_predic)\n",
    "print ('Confusion Matrix :')\n",
    "print(results)\n",
    "print ('Accuracy Score is',accuracy_score(X_actual, Y_predic))\n",
    "print ('Classification Report : ')\n",
    "print (classification_report(X_actual, Y_predic))\n",
    "print('AUC-ROC:',roc_auc_score(X_actual, Y_predic))\n",
    "print('LOGLOSS Value is',log_loss(X_actual, Y_predic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
