{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Getting the Dataset\n",
    "\n",
    "http://www.bbci.de/competition/iii/desc_IVa.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEBUG:matplotlib:CACHEDIR=/home/nahuel/.cache/matplotlib\n",
      "DEBUG:matplotlib.font_manager:Using fontManager instance from /home/nahuel/.cache/matplotlib/fontlist-v310.json\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n",
      "DEBUG:matplotlib.pyplot:Loaded backend module://ipykernel.pylab.backend_inline version unknown.\n"
     ]
    }
   ],
   "source": [
    "from __future__ import division\n",
    "\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.io import loadmat\n",
    "import matplotlib as mpl\n",
    "from wyrm import processing as proc\n",
    "from wyrm.types import Data\n",
    "from wyrm import plot\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from os import path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se carga data txt Class-Time x Channel (298458 x 118)\n",
    "def load_data(sujeto, nro_tr):\n",
    "    \n",
    "    data_cnt_txt = np.loadtxt('../../DATA/Competencia BCI/III/Dataset_IV/txt/'+sujeto+'/100Hz/data_set_IVa_'+sujeto+'_cnt.txt')\n",
    "    #Traspuesta Channel x Class-Time (118 x 298458)\n",
    "    data_cnt_txt = data_cnt_txt.transpose()\n",
    "\n",
    "    #Se carga 280 etiquetas de Class\n",
    "    data_lab_txt = np.loadtxt('../../DATA/Competencia BCI/III/Dataset_IV/txt/'+sujeto+'/100Hz/data_set_IVa_'+sujeto+'_mrk.txt')\n",
    "\n",
    "    #Se carga 100 etiquetas TRUE LABELS\n",
    "    TRUE_LABELS = '../../DATA/Competencia BCI/III/Dataset_IV/txt/'+sujeto+'/TRUE_LABELS.txt'\n",
    "\n",
    "    true_labels = np.loadtxt(TRUE_LABELS).astype('int')\n",
    "    #Convertimos los -1 a 0\n",
    "    true_labels[true_labels == 2] = 0\n",
    "\n",
    "    true_labels = true_labels[nro_tr:]\n",
    "\n",
    "    #Se castea a Int (1- Left, 2- Foot, 0- Test)\n",
    "    data_lab_txt = np.nan_to_num(data_lab_txt)\n",
    "    data_lab_txt = data_lab_txt.astype('int')\n",
    "\n",
    "    #La primer columna es de posiciones de eventos\n",
    "    posicion = data_lab_txt[:,0]\n",
    "    #La segunda columna es de labels\n",
    "    data_lab = data_lab_txt[:,1]\n",
    "\n",
    "    flag=1\n",
    "    for pos in posicion:\n",
    "        #Nos quedamos con muestras de 60 frames por evento para los 118 channels\n",
    "        aux = np.array( [ data_cnt_txt[:, pos-30:pos+30] ] )\n",
    "        if flag == 1:\n",
    "            data_cnt=aux\n",
    "            flag=0\n",
    "        else:\n",
    "            data_cnt=np.append(data_cnt, aux, axis=0)\n",
    "\n",
    "\n",
    "    #Modificamos el orden de las dimensiones como Class x Time x Channel (280 x 60 x 118)\n",
    "    data_cnt=data_cnt.swapaxes(-1, -2)\n",
    "\n",
    "    #Los primeros 168 Class son de train como Class x Time x Channel (168 x 60 x 118)\n",
    "    data_train=data_cnt[:nro_tr]\n",
    "    #El resto de las Class son de test como Class x Time x Channel (112 x 60 x 118)\n",
    "    data_test=data_cnt[nro_tr:]\n",
    "\n",
    "\n",
    "    #Las labes validas son para el conjunto de train\n",
    "    data_lab = data_lab[:nro_tr]\n",
    "    data_lab[data_lab == 2] = 0\n",
    "    \n",
    "    return data_train, data_lab, data_test, true_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "aa\n",
      "train:  (168, 60, 118)\n",
      "test:  (112, 60, 118)\n",
      "al\n",
      "train:  (224, 60, 118)\n",
      "test:  (56, 60, 118)\n"
     ]
    }
   ],
   "source": [
    "#    #tr  #te\n",
    "#aa  168 112\n",
    "#al  224  56\n",
    "#av  84  196\n",
    "#aw  56  224\n",
    "#ay  28  252\n",
    "\n",
    "data_train_aux, data_lab_aux, data_test_aux, true_labels_aux = load_data('aa', 168)\n",
    "\n",
    "print('aa')\n",
    "print('train: ', data_train_aux.shape)\n",
    "print('test: ',data_test_aux.shape)\n",
    "\n",
    "data_train = data_train_aux\n",
    "data_lab = data_lab_aux\n",
    "data_test = data_test_aux\n",
    "true_labels = true_labels_aux\n",
    "\n",
    "data_train_aux, data_lab_aux, data_test_aux, true_labels_aux = load_data('al', 224)\n",
    "\n",
    "data_train=np.append(data_train, data_train_aux, axis=0)\n",
    "data_lab=np.append(data_lab, data_lab_aux, axis=0)\n",
    "data_test=np.append(data_test, data_test_aux, axis=0)\n",
    "true_labels=np.append(true_labels, true_labels_aux, axis=0)\n",
    "\n",
    "print('al')\n",
    "print('train: ', data_train_aux.shape)\n",
    "print('test: ',data_test_aux.shape)\n",
    "\n",
    "data_train_aux, data_lab_aux, data_test_aux, true_labels_aux = load_data('av', 84)\n",
    "\n",
    "data_train=np.append(data_train, data_train_aux, axis=0)\n",
    "data_lab=np.append(data_lab, data_lab_aux, axis=0)\n",
    "data_test=np.append(data_test, data_test_aux, axis=0)\n",
    "true_labels=np.append(true_labels, true_labels_aux, axis=0)\n",
    "\n",
    "print('av')\n",
    "print('train: ', data_train_aux.shape)\n",
    "print('test: ',data_test_aux.shape)\n",
    "\n",
    "data_train_aux, data_lab_aux, data_test_aux, true_labels_aux = load_data('aw', 56)\n",
    "\n",
    "data_train=np.append(data_train, data_train_aux, axis=0)\n",
    "data_lab=np.append(data_lab, data_lab_aux, axis=0)\n",
    "data_test=np.append(data_test, data_test_aux, axis=0)\n",
    "true_labels=np.append(true_labels, true_labels_aux, axis=0)\n",
    "\n",
    "print('aw')\n",
    "print('train: ', data_train_aux.shape)\n",
    "print('test: ',data_test_aux.shape)\n",
    "\n",
    "data_train_aux, data_lab_aux, data_test_aux, true_labels_aux = load_data('ay', 28)\n",
    "\n",
    "data_train=np.append(data_train, data_train_aux, axis=0)\n",
    "data_lab=np.append(data_lab, data_lab_aux, axis=0)\n",
    "data_test=np.append(data_test, data_test_aux, axis=0)\n",
    "true_labels=np.append(true_labels, true_labels_aux, axis=0)\n",
    "\n",
    "print('ay')\n",
    "print('train: ', data_train_aux.shape)\n",
    "print('test: ',data_test_aux.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convertimos a wyrm Data - Set Train\n",
    "#Cargamos data training\n",
    "data = data_train\n",
    "labels = data_lab\n",
    "\n",
    "#Creamos axes con enumerados de la misma longitud que data Class x Time x Channel\n",
    "axes = [np.arange(i) for i in data.shape]\n",
    "#Se completa la dimension Class con labels\n",
    "axes[0] = labels\n",
    "#Se convierte a str la dimension Channel\n",
    "#axes[2] = [str(i) for i in range(data.shape[2])]\n",
    "axes[2] = ['Fp1', 'AFp1', 'Fpz', 'AFp2', 'Fp2', 'AF7', 'AF3', 'AF4', 'AF8', 'FAF5', 'FAF1', 'FAF2', 'FAF6', 'F7', 'F5', 'F3', 'F1', 'Fz', 'F2', 'F4', 'F6', 'F8', 'FFC7', 'FFC5', 'FFC3', 'FFC1', 'FFC2', 'FFC4', 'FFC6', 'FFC8', 'FT9', 'FT7', 'FC5', 'FC3', 'FC1', 'FCz', 'FC2', 'FC4', 'FC6', 'FT8', 'FT10', 'CFC7', 'CFC5', 'CFC3', 'CFC1', 'CFC2', 'CFC4', 'CFC6', 'CFC8', 'T7', 'C5', 'C3', 'C1', 'Cz', 'C2', 'C4', 'C6', 'T8', 'CCP7', 'CCP5', 'CCP3', 'CCP1', 'CCP2', 'CCP4', 'CCP6', 'CCP8', 'TP9', 'TP7', 'CP5', 'CP3', 'CP1', 'CPz', 'CP2', 'CP4', 'CP6', 'TP8', 'TP10', 'PCP7', 'PCP5', 'PCP3', 'PCP1', 'PCP2', 'PCP4', 'PCP6', 'PCP8', 'P9', 'P7', 'P5', 'P3', 'P1', 'Pz', 'P2', 'P4', 'P6', 'P8', 'P10', 'PPO7', 'PPO5', 'PPO1', 'PPO2', 'PPO6', 'PPO8', 'PO7', 'PO3', 'PO1', 'POz', 'PO2', 'PO4', 'PO8', 'OPO1', 'OPO2', 'O1', 'Oz', 'O2', 'OI1', 'OI2', 'I1', 'I2' ]\n",
    "\n",
    "names = ['Class', 'Time', 'Channel']\n",
    "units = ['#', 'ms', '#']\n",
    "dat_train = Data(data=data, axes=axes, names=names, units=units)\n",
    "dat_train.fs = 100\n",
    "dat_train.class_names = ['Left', 'Foot']\n",
    "\n",
    "#Convertimos a wyrm Data - Set Test\n",
    "#Cargamos data test\n",
    "data = data_test\n",
    "\n",
    "#Creamos axes con enumerados de la misma longitud que data Class x Time x Channel\n",
    "axes = [np.arange(i) for i in data.shape]\n",
    "#Se convierte a str la dimension Channel\n",
    "axes[2] = [str(i) for i in range(data.shape[2])]\n",
    "names = ['Epoch', 'Time', 'Channel']\n",
    "units = ['#', 'ms', '#']\n",
    "dat_test = Data(data=data, axes=axes, names=names, units=units)\n",
    "dat_test.fs = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_csp_pattern(a):\n",
    "    # get symmetric min/max values for the color bar from first and last column of the pattern\n",
    "    maxv = np.max(np.abs(a[:, [0, -1]]))\n",
    "    minv = -maxv\n",
    "    \n",
    "    im_args = {'interpolation' : 'None', \n",
    "           'vmin' : minv, \n",
    "           'vmax' : maxv\n",
    "           }\n",
    "\n",
    "    # plot\n",
    "    ax1 = plt.subplot2grid((1,11), (0,0), colspan=5)\n",
    "    ax2 = plt.subplot2grid((1,11), (0,5), colspan=5)\n",
    "    ax3 = plt.subplot2grid((1,11), (0,10))\n",
    "\n",
    "    ax1.imshow(a[:, 0].reshape(8, 8), **im_args)\n",
    "    ax1.set_title('Pinky')\n",
    "\n",
    "    ax = ax2.imshow(a[:, -1].reshape(8, 8), **im_args)\n",
    "    ax2.set_title('Tongue')\n",
    "\n",
    "    plt.colorbar(ax, cax=ax3)\n",
    "    plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filtros(data):\n",
    "    dat = data.copy()\n",
    "    \n",
    "    #Mitad de la frecuencia\n",
    "    fs_n = dat.fs / 2\n",
    "    \n",
    "    #Se aplica filtros\n",
    "    b, a = proc.signal.butter(5, [13 / fs_n], btype='low')\n",
    "    dat = proc.filtfilt(dat, b, a)\n",
    "    \n",
    "    b, a = proc.signal.butter(5, [9 / fs_n], btype='high')\n",
    "    dat = proc.filtfilt(dat, b, a)\n",
    "    return dat\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data, filt=None):\n",
    "    #Se aplican los filtros\n",
    "    dat=filtros(data)\n",
    "    #dat=data\n",
    "    \n",
    "    #Se toma una muestra de 50 cada 1000 (fs_n = 1000) (278 x 150 x 64)\n",
    "    dat = proc.subsample(dat, 50)\n",
    "        \n",
    "    if filt is None:\n",
    "        #Calcula el patrón espacial común (CSP) para dos clases.\n",
    "        filt, pattern, _ = proc.calculate_csp(dat)\n",
    "        #Grafica csp_pattern\n",
    "        #plot_csp_pattern(pattern)\n",
    "        \n",
    "    #Aplica el CSP\n",
    "    dat = proc.apply_csp(dat, filt)\n",
    "    dat = proc.variance(dat)\n",
    "    dat = proc.logarithm(dat)\n",
    "    return dat, filt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Se calcula el vector de caracteristicas para los conjuntos de train y test\n",
    "fv_train, filt = preprocess(dat_train)\n",
    "fv_test, _ = preprocess(dat_test, filt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Entrenamiento con LDA clasificador.\n",
    "cfy = proc.lda_train(fv_train)\n",
    "\n",
    "#Aplicar vector de características al clasificador LDA.\n",
    "result = proc.lda_apply(fv_test, cfy)\n",
    "\n",
    "#Normaliza resultados\n",
    "#Si es > 0 = 1 sino -1\n",
    "result = (np.sign(result)).astype('int')\n",
    "#Convertimos los -1 a 0\n",
    "result[result == -1] = 0\n",
    "\n",
    "#Se compara los resultados del modelo contra los TRUE LABELS\n",
    "print ('LDA Accuracy %.2f%%' % ((result == true_labels).sum() / len(result)) ) \n",
    "\n",
    "print(result.shape)\n",
    "#print(result)\n",
    "print(true_labels.shape)\n",
    "#print(true_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import metrics as met\n",
    "\n",
    "print( met.confusion_matrix(true_labels, result) )\n",
    "print( \"Recall: \", met.recall_score(true_labels, result, average=None) )\n",
    "print( \"Precision: \", met.precision_score(true_labels, result, average=None) )\n",
    "print( \"F1: \", met.f1_score(true_labels, result, average=None) )\n",
    "print( \"Acurracy: \", met.accuracy_score(true_labels, result) )\n",
    "\n",
    "tn, fp, fn, tp = met.confusion_matrix(true_labels, result).ravel()\n",
    "print(tn, fp, fn, tp)\n",
    "\n",
    "print(met.classification_report(true_labels, result))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
